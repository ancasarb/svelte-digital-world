{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dataclasses-json in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (0.5.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from dataclasses-json) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from dataclasses-json) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from dataclasses-json) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json) (4.6.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json) (1.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/ancasarb/.pyenv/versions/3.9.13/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.0/157.0 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-macosx_11_0_arm64.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.0/123.0 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.1.0 idna-3.4 requests-2.31.0 urllib3-2.0.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/ancasarb/.pyenv/versions/3.9.13/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/ancasarb/.pyenv/versions/3.9.13/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting html5lib\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six>=1.9 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from html5lib) (1.16.0)\n",
      "Installing collected packages: webencodings, html5lib\n",
      "Successfully installed html5lib-1.1 webencodings-0.5.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/ancasarb/.pyenv/versions/3.9.13/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandas\n",
      "  Downloading pandas-2.0.2-cp39-cp39-macosx_11_0_arm64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.20.3\n",
      "  Downloading numpy-1.25.0-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/ancasarb/.pyenv/versions/3.9.13/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.25.0 pandas-2.0.2 pytz-2023.3 tzdata-2023.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/ancasarb/.pyenv/versions/3.9.13/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install dataclasses-json\n",
    "!python3 -m pip install requests\n",
    "!python3 -m pip install beautifulsoup4\n",
    "!python3 -m pip install html5lib\n",
    "!python3 -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from dataclasses_json import dataclass_json\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass_json\n",
    "@dataclass\n",
    "class ArticleURL:\n",
    "    page_number: int\n",
    "    url: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass_json\n",
    "@dataclass\n",
    "class ArticleMetadata:\n",
    "    page: int\n",
    "    url: str\n",
    "    creation_date: datetime\n",
    "    author: str\n",
    "    title: str\n",
    "    keywords: str\n",
    "    verdict: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_article_urls() -> List[ArticleURL]:\n",
    "    page_number = 0\n",
    "    article_urls = []\n",
    "\n",
    "    while True:\n",
    "        page_number = page_number + 1\n",
    "        r = get(\n",
    "            f\"https://www.reuters.com/news/archive/factchecknew?view=page&page={page_number}&pageSize=10\"\n",
    "        )\n",
    "        soup = BeautifulSoup(r.content, \"html5lib\")\n",
    "\n",
    "        a_elements = soup.findAll(\n",
    "            \"a\",\n",
    "            href=lambda value: value\n",
    "            and (\n",
    "                value.startswith(\"/article/factcheck\")\n",
    "                or value.startswith(\"/article/fact-check\")\n",
    "                or value.startswith(\"/article/id\")\n",
    "                or (\"/fact-check\" in value and value != \"/fact-check\")\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        hrefs = list(dict.fromkeys([a[\"href\"] for a in a_elements]))\n",
    "\n",
    "        new_article_urls = [\n",
    "            ArticleURL(page_number, f\"https://www.reuters.com{a}\") for a in hrefs\n",
    "        ]\n",
    "\n",
    "        if not new_article_urls:\n",
    "            break\n",
    "        else:\n",
    "            article_urls.extend(new_article_urls)\n",
    "    return article_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_article_metadata(article: ArticleURL) -> Optional[ArticleMetadata]:\n",
    "    r = get(article.url)\n",
    "    soup = BeautifulSoup(r.content, \"html5lib\")\n",
    "\n",
    "    article_date = find_metadata_tag(soup, \"analyticsAttributes.articleDate\")\n",
    "    date_time_obj = datetime.strptime(article_date, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    if date_time_obj.year == 2022:\n",
    "        keywords = find_metadata_tag(soup, \"keywords\")\n",
    "        author = find_metadata_tag(soup, \"analyticsAttributes.author\")\n",
    "        title = find_metadata_tag(soup, \"analyticsAttributes.title\")\n",
    "        verdict = soup.find(\n",
    "            \"h2\", text=lambda value: value and value.startswith(\"VERDICT\")\n",
    "        )\n",
    "        if verdict is not None:\n",
    "            verdict_type = verdict.findNext(\"p\").getText().split(\".\")[0]\n",
    "        else:\n",
    "            verdict = soup.find(\n",
    "                \"p\", text=lambda value: value and value.startswith(\"VERDICT\")\n",
    "            )\n",
    "            if verdict is not None:\n",
    "                verdict_type = verdict.getText().replace(\"VERDICT\", \"\").split(\".\")[0]\n",
    "            else:\n",
    "                verdict = soup.find(\n",
    "                    \"p\", text=lambda value: value and value.startswith(\"Verdict\")\n",
    "                )\n",
    "                if verdict is not None:\n",
    "                    verdict_type = verdict.findNext(\"p\").getText().split(\".\")[0]\n",
    "                else:\n",
    "                    print(\"Ignoring article \" + article.url + \" as it doesn't have a verdict\")\n",
    "                    return None\n",
    "\n",
    "        return ArticleMetadata(\n",
    "            page=article.page_number,\n",
    "            url=article.url,\n",
    "            creation_date=date_time_obj,\n",
    "            title=title,\n",
    "            author=author,\n",
    "            keywords=keywords,\n",
    "            verdict=verdict_type\n",
    "        )\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metadata_tag(element: BeautifulSoup, key: str) -> str:\n",
    "    output = element.find(\"meta\", attrs={\"name\": key})\n",
    "    return output[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_urls = retrieve_article_urls()\n",
    "\n",
    "articles_metadata = []\n",
    "for article_url in article_urls:\n",
    "    metadata = retrieve_article_metadata(article_url)\n",
    "    if metadata is not None:\n",
    "        articles_metadata.append(metadata)\n",
    "\n",
    "df = DataFrame(articles_metadata)\n",
    "df.to_csv(\"../data/fact_check.csv\", sep=\",\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
